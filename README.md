# Adaptive Database Framework

A self-adaptive database framework that autonomously ingests a live JSON data stream, infers field types, classifies every field into **MySQL** (structured) or **MongoDB** (semi-structured), and routes records to the appropriate backend â€” all without hardcoded schemas.


---

## ğŸ“š Project Overview

The system consumes health-tracker JSON records from a FastAPI data stream, normalises naming conventions, observes field patterns through statistical analysis, and dynamically decides which database backend each field belongs to. Linking fields (`username`, `sys_ingested_at`) are stored in **both** backends to enable cross-database joins.

### Key Capabilities

| Capability | Description |
|---|---|
| **Dynamic Schema Inference** | No predefined schemas â€” field types discovered from data |
| **Adaptive Placement** | Heuristic rules decide SQL vs MongoDB per field |
| **Cross-DB Linking** | `username` + `sys_ingested_at` in both backends for joins |
| **Metadata Persistence** | Classification decisions survive process restarts |
| **Bi-temporal Timestamps** | `t_stamp` (client) + `sys_ingested_at` (server) |

---

## ğŸ—ï¸ Architecture

The codebase is organized into **4 topics** + a final orchestrator:

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚  Data Stream API â”‚
                         â”‚  (FastAPI :8000) â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚  raw JSON records
                                  â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚                    IngestAndClassify                       â”‚
 â”‚                                                            â”‚
 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
 â”‚  â”‚ TOPIC 1 â€” NORMALIZATION              src/normalization/ â”‚
 â”‚  â”‚  FieldNormalizer Â· TypeDetector Â· RecordNormalizerâ”‚      â”‚
 â”‚  â”‚  â€¢ camelCase/PascalCase â†’ snake_case             â”‚      â”‚
 â”‚  â”‚  â€¢ Detect IP vs float, UUID, datetime            â”‚      â”‚
 â”‚  â”‚  â€¢ Inject sys_ingested_at timestamp              â”‚      â”‚
 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
 â”‚                     â”‚ normalized records                    â”‚
 â”‚                     â–¼                                       â”‚
 â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
 â”‚               â”‚  BUFFER   â”‚  in-memory staging              â”‚
 â”‚               â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                                 â”‚
 â”‚                     â”‚ flush (size or timeout)               â”‚
 â”‚                     â–¼                                       â”‚
 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
 â”‚  â”‚ TOPIC 2 â€” ANALYSIS & CLASSIFICATION  src/analysis/      â”‚
 â”‚  â”‚  FieldAnalyzer Â· FieldStats Â· Classifier         â”‚      â”‚
 â”‚  â”‚  â€¢ Track presence %, type stability, nesting     â”‚      â”‚
 â”‚  â”‚  â€¢ Apply heuristic rules â†’ PlacementDecision     â”‚      â”‚
 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
 â”‚                     â”‚ decisions                             â”‚
 â”‚                     â–¼                                       â”‚
 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
 â”‚  â”‚ TOPIC 3 â€” STORAGE                   src/storage/        â”‚
 â”‚  â”‚  MySQLClient Â· MongoClient Â· RecordRouter        â”‚      â”‚
 â”‚  â”‚  â€¢ Dynamic CREATE TABLE / ALTER TABLE            â”‚      â”‚
 â”‚  â”‚  â€¢ Split record â†’ SQL part + Mongo part          â”‚      â”‚
 â”‚  â”‚  â€¢ Batch insert into both backends               â”‚      â”‚
 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
 â”‚                     â”‚                                       â”‚
 â”‚                     â–¼                                       â”‚
 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
 â”‚  â”‚ TOPIC 4 â€” PERSISTENCE               src/persistence/   â”‚
 â”‚  â”‚  MetadataStore                                   â”‚      â”‚
 â”‚  â”‚  â€¢ Save/load decisions, stats, mappings to JSON  â”‚      â”‚
 â”‚  â”‚  â€¢ Enables restart without re-analysis           â”‚      â”‚
 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Classification Rules

| # | Condition | â†’ Backend |
|---|---|---|
| 1 | Field is `username`, `sys_ingested_at`, or `t_stamp` | **BOTH** |
| 2 | Value is nested (dict / list) | **MongoDB** |
| 3 | Presence â‰¥ 70% AND type stability â‰¥ 90% | **SQL** |
| 4 | Everything else | **MongoDB** |

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.12+**
- **Docker & Docker Compose**
- **Poetry** (`pip install poetry`)

### 1 Â· Start databases

```bash
docker-compose up -d          # MySQL 8.0  +  MongoDB 7.0
```

### 2 Â· Install dependencies

```bash
poetry install
```

### 3 Â· Configure environment

```bash
cp .env.example .env
# Edit .env if you need non-default ports/passwords
```

### 4 Â· Run the data stream API (separate terminal)

```bash
git clone https://github.com/YogeshKMeena/Course_Resources.git
cd Course_Resources/CS432_Databases/Assignments/T2
pip install -r requirements.txt
uvicorn simulation_code:app --reload --port 8000
```

### 5 Â· Run the pipeline

```bash
# Ingest 100 records
poetry run python -m src.cli ingest --count 100

# Or run continuously
poetry run python -m src.cli ingest --continuous --interval 0.5

# Check status
poetry run python -m src.cli status

# View placement decisions
poetry run python -m src.cli decisions
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ normalization/               # Topic 1
â”‚   â”‚   â”œâ”€â”€ field_normalizer.py      #   FieldNormalizer  â€” name canonicalization
â”‚   â”‚   â”œâ”€â”€ type_detector.py         #   TypeDetector     â€” semantic type detection
â”‚   â”‚   â””â”€â”€ record_normalizer.py     #   RecordNormalizer â€” full record pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                    # Topic 2
â”‚   â”‚   â”œâ”€â”€ field_stats.py           #   FieldStats       â€” per-field statistics
â”‚   â”‚   â”œâ”€â”€ field_analyzer.py        #   FieldAnalyzer    â€” observation engine
â”‚   â”‚   â”œâ”€â”€ decision.py              #   PlacementDecision, Backend enum, thresholds
â”‚   â”‚   â””â”€â”€ classifier.py            #   Classifier       â€” heuristic rules
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                     # Topic 3
â”‚   â”‚   â”œâ”€â”€ mysql_client.py          #   MySQLClient      â€” dynamic DDL + inserts
â”‚   â”‚   â”œâ”€â”€ mongo_client.py          #   MongoClient      â€” document inserts + indexes
â”‚   â”‚   â””â”€â”€ record_router.py         #   RecordRouter     â€” split & route records
â”‚   â”‚
â”‚   â”œâ”€â”€ persistence/                 # Topic 4
â”‚   â”‚   â””â”€â”€ metadata_store.py        #   MetadataStore    â€” JSON-based persistence
â”‚   â”‚
â”‚   â”œâ”€â”€ config.py                    # Configuration (env vars / .env)
â”‚   â”œâ”€â”€ ingest_and_classify.py       # â˜… IngestAndClassify orchestrator
â”‚   â””â”€â”€ cli.py                       # CLI entry point
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py                  # Shared fixtures
â”‚   â””â”€â”€ test_ingest_and_classify.py  # Test skeleton
â”‚
â”œâ”€â”€ docker-compose.yml               # MySQL 8.0 + MongoDB 7.0
â”œâ”€â”€ pyproject.toml                   # Poetry config + ruff/mypy/pytest
â”œâ”€â”€ .env.example                     # Environment template
â”œâ”€â”€ .pre-commit-config.yaml          # Ruff + mypy hooks
â””â”€â”€ .github/
    â”œâ”€â”€ workflows/ci.yml             # Lint â†’ Test CI pipeline
    â””â”€â”€ PULL_REQUEST_TEMPLATE.md
```

---

## ğŸ§ª Testing

```bash
# All tests
poetry run pytest

# With coverage report
poetry run pytest --cov=src --cov-report=term-missing

# Specific topic
poetry run pytest tests/test_normalization.py
poetry run pytest tests/test_analysis.py
poetry run pytest tests/test_storage.py
poetry run pytest tests/test_persistence.py

# Integration tests only
poetry run pytest -m integration
```

---

## ğŸ”§ Development

### Code Quality

```bash
poetry run ruff format .          # Auto-format
poetry run ruff check . --fix     # Lint + auto-fix
poetry run mypy src/              # Type checking
```

### Pre-commit Hooks

```bash
poetry run pre-commit install     # One-time setup
poetry run pre-commit run --all-files   # Manual run
```

### Branching Convention

```
main                â† stable, passing CI
â”œâ”€â”€ topic1/â€¦        â† normalization work
â”œâ”€â”€ topic2/â€¦        â† analysis & classification work
â”œâ”€â”€ topic3/â€¦        â† storage work
â””â”€â”€ topic4/â€¦        â† persistence work
```

---



## ğŸ“– References

- [Course Project Document](./Databases_CS432__2026_%20Track%202.pdf)
- [Data Stream API (Course Repo)](https://github.com/YogeshKMeena/Course_Resources/tree/main/CS432_Databases/Assignments/T2)
- [API Endpoint](http://127.0.0.1:8000/GET/record/{count})


